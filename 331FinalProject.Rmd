---
title: "STAT 331 Final Project"
author: "Maxine, Estella, Judy, Weiwei"
date: "04/12/2021"
header-includes:
  - \DeclareUnicodeCharacter{FF0C}{$\bullet$}
  - \DeclareUnicodeCharacter{3000}{$\bullet$}
link-citations: yes
linkcolor: blue
output:
  pdf_document:
    number_sections: yes
    toc_depth: 1
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\newpage
\tableofcontents
\newpage


# Summary
A maximum of 200 words describing the objective of the report, an overview of the statistical analysis, and summary of the main results.

# Objective 
We are looking to investigate the most influential factors that contribute to the average leukocyte telomere length in a person. We would like to especially look for human-adjustable factors such as whether a person smokes or exposure to persistent organic pollutants. 


# Exploratory Data Analysis

```{r dataset, echo=FALSE}
# import dataset

# CHANGE ABSOLUTE PATH
# setwd("~/Desktop/stat341/R331project/data")
# setwd("~/School/4A/STAT 331/R331project/data")
# setwd("~/Desktop/R331project/data")
# setwd("C:/Users/huawei/Desktop/R331project/data")

pollutants_raw <- read.csv("pollutants.csv", header = TRUE)
```
```{r cleandataset, echo=FALSE}
# Mxn's work
# clean the pollutants dataframe
pollutants <- subset(pollutants_raw , select = -X)

# deal with categorical data

# 1 = Less Than 9th Grade or 9-11th Grade (Includes 12th grade with no diploma) 
# 2 = High School Grad/GED or Equivalent
# 3 = Some College or AA degree
# 4 = College Graduate
edu_factor=factor(pollutants$edu_cat)

# 1 = Other Race (Including Multi-Racial);
# 2 = Mexican American; 
# 3 = Non-Hispanic Black; 
# 4 = Non-Hispanic White
race_factor=factor(pollutants$race_cat, 
                   labels = c("Other", "Mexican", "Black", "White"))

# 0 = does not currently smoke; 
# 1 = currently smokes
smoke_factor=factor(pollutants$smokenow, labels = c("Non-Smoker", "Smoker"))

# 0 = female, 1 = male
gender_factor=factor(pollutants$male, labels = c("female", "male"))


pollutants$edu_cat = edu_factor
pollutants$race_cat = race_factor
pollutants$smokenow = smoke_factor
pollutants$male = gender_factor
```

The covariates of interest from the provided dataset are 
```{r covariatenames}
names(pollutants)
```
Note that "edu_cat", "race_cat", "male", "smokenow" are categorical values and the rest are continuous. 

## Data Distribution
We shall now investigate the distribution of covariates from the supplied data.

From the output of summary statistics on the covariates (see in appendix \ref{datasummary}), we observed that all values are non-negative and there are more observations with values close to 0 than values with large magnitude across all covariates.

Now we shall have a closer look at the distribution of individual covariate. For categorical data, 

```{r histograms, echo=FALSE, fig.align = "center", fig.dim = c(6,4.25)}
# Mxn's work
# put bargraphs for categorical data onto one picture
par(mfrow=c(2,2))

plot(edu_factor, 
     main="Distribution of Education",
     xlab="Education Level Count")

plot(race_factor, 
     main="Distribution of Race",
     xlab="Race Count")

plot(smoke_factor, 
     main="Distribution of Current Smokers",
     xlab="Smokers Count")

plot(gender_factor, 
     main="Distribution of Gender",
     xlab="Gender Count")
```

We may observe from the bar graphs that there are more data about non-smokers than smokers and white people than other races. There are more entries for lower education than higher, and more female than male. However, the distribution of gender and education is relatively close.

Now for continuous data, we made boxplots to see the distribution of these covariates, the plots can be found in the appendix \ref{largeboxplots}. From these plots, we notice some extreme outliers in some concentration values of PCBs, Dioxins, and Furan. The maximum values are sometimes over double the magnitude of the second largest. 

However, with a little investigation in the appendix \ref{findoutliers}, we see that the extreme outliers across different types of PCB mostly came from one observation.

```{r outlier}
pollutants[436, 3:12]
```

This observation contributes to the maximum value for PCB1 to PCB6, as well as PCB8 and PCB9


Similarly, the most extreme outliers from Dioxin and Furan also came from the same entry of data:

* Entry 285 contain the highest value for Dioxin 1 and 3, which are the two extreme outliers as we can see from the boxplots
* Entry 559 contain the highest value for Furan 2 and 4, where Furan 4 has an extreme outlier

Other covariates, as we see from the boxplots, do not have outliers that are as extreme as those from pollutant data. We further observe that they do not have a common entry that contributes to the outliers.


## Multicolinearity
We learned that severe multicollinearity between covariates could result in unstable coefficient estimates and inflated standard errors. Therefore, in this section, we will investigate correlations among values that we may expect multicollinearity to appear, such as between different types of organic pollutants POP_PCB1--11, POP_dioxin1-3, Pop_furan1--4, as well as white blood cell components.

To obtain the heatmaps that visualize correlations among covariates, we first computed Spearman correlations for each pair of covariates of interest and represented the measured values through gradients of a color scheme. In our example, blue refers to positive correlations and red, negative. Furthermore, the darker colours signify a higher correlation among the covariates. Finally, we clustered variables with higher correlations together such that the covariates within the same rectangles are highly correlated such that they may have dependencies on each other. 

### Correlation among Persistent Pollution
```{r chemcorrelations, echo=FALSE, fig.align = "center", fig.dim = c(5,6)}
# Estella's work 1
library(corrplot)
library(ggplot2)

POP_chemicals = c("POP_PCB1", "POP_PCB2","POP_PCB3", "POP_PCB4",
                  "POP_PCB5", "POP_PCB6","POP_PCB7", "POP_PCB8",
                  "POP_PCB9", "POP_PCB10", "POP_PCB11", 
                  "POP_dioxin1", "POP_dioxin2","POP_dioxin3",
                  "POP_furan1", "POP_furan2","POP_furan3","POP_furan4")

POP_chemicals_data <- pollutants [, POP_chemicals]
cc = cor(POP_chemicals_data , method = "spearman")

# cluster my POP_PCB so that those with similar patterns
# of correlation coefficients are closer together.
# https://jkzorz.github.io/2019/06/11/Correlation-heatmaps.html
corrplot(cc, tl.col = "black", order = "hclust", hclust.method = "average",
         addrect = 11, tl.cex = 0.7)
```

Based on the above plot, we noticed the correlations mostly exist among the organic pollutants of the same kind. Specifically, the correlations among POP_PCB3,6,7 and POP_PCB8,9,4,5,1,2 are higher than others.


### Correlation between White Blood Cells
```{r wbccorrelations, echo=FALSE, fig.align = "center", fig.dim = c(4,4)}
# mxn's work
WBC = c("whitecell_count", "lymphocyte_pct","monocyte_pct", 
        "eosinophils_pct", "basophils_pct", "neutrophils_pct")
WBC_data <- pollutants [, WBC]
cc = cor(WBC_data , method = "spearman")
corrplot(cc, tl.col = "black", order = "hclust", hclust.method = "average", tl.cex = 0.7)
```

From the graph above, we see that there is no strong positive correlation among the components of white blood cells, however, there is a strong negative correlation between lymphocytes and eosinophils percentage in the given data.

We shall omit the analysis on correlations between other covariate from this section as we do not expect personal health data such as BMI or years of smoke to have a logical significant correlation with each other, white blood cell data, or exposure to pollutants.

To further investigate how these listed correlations affect the observed data, we shall consider adding interaction terms to our model, and performed p-test to check their statistical significance.


# Methods
Describe your statistical analysis: What is your model? Did you use any transformations or extensions of the basic multiple linear regression model? How did you select a model? Does the model fit the data well? Are the necessary assumptions met? Be sure to explain and justify your decisions.

## Linear Model Assumptions
Since we have no access to data collection, we shall proceed by assuming that the independence assumption is satisfied.

As for the normality assumption, as the given dataset is relatively large, we may assume the data is approximately Normally distributed due to the Central Limit Theorem.

Now to assess whether any covariate has a nonlinearity relationship with the outcome in the multiple linear regression model, we used added-variable plots(avPlot), as shown in appendix \ref{AvPlots}. The plots isolate the relationship between the outcome and each of the covariates after adjusting for the other covariate. If the plot of the outcome versus a covariate x has a nonlinear shape, it may indicate a regression model with a higher power of this variable, for example, $x^2$. With the given data, we see from the avPlots that all plots have a linear shape, thus the outcome is expected to have a linear relationship with all of the covariates. Therefore, the models constructed in this report do not consider non-linear terms.

## Heteroskedasticity
We also need to verify the equal variance(heteroscedasticity) assumption. As shown in the appendix \ref{Residuals vs Fitted plot}, if there are evident patterns in the residuals, we might not be able to simply trust the results. Fortunately, we can see that the random residuals are uncorrelated and uniform.

## Finding the model

We shall first split the data into training and testing set to ensure the final model is well-generalized without problems such as overfitting or underfitting.

```{r splitdata}
set.seed(23)
train_idx <- sample(nrow(pollutants), 650, replace = FALSE, prob = NULL)
train_data <- pollutants[train_idx,]
test_data <- pollutants[-train_idx, ]
```

### Investigate Interactions

As we have seen in the EDA section, we would like to investigate interactions among pollutants as well as white blood cell-related data. By building a large linear model and filtering the interactions with p values $\leq 0.05$, we have selected the following potential interaction terms that we may consider in the model building process:

```{r chemwbcinteractions, echo=FALSE}
# Estella and mxn' work
chemicals_WBC = append(POP_chemicals, WBC)
f <- as.formula(
  paste("length", paste("(", paste(chemicals_WBC, collapse = "+"), ")^2"), sep="~"))
m_chemwbc <- lm(f, data = pollutants)
```
```{r selectinteractions, echo=FALSE}
# Estella and mxn' work
# setting threshold of pvalue to be 0.05 and assess possible interaction terms
pvalues <- summary(m_chemwbc)$coefficients[26:nrow(summary(m_chemwbc)$coefficients),4]
p_threshold = 0.05
selected <- which(pvalues <= p_threshold)
```

```{r printselected}
names(selected)
```

We now shall select a linear model with all covariate and interaction terms, we can find the summary of the resulting model in the appendix \ref{modelsummary1}. 

```{r buildmodelinteractions, echo=FALSE}
# stepwise parameters selection with any interaction terms
M0 <- lm(length ~ 1, data = train_data) # minimal model

# tail to remove length column
single <- paste(tail(colnames(train_data),-1), collapse = " + ")
# tail to remove intercept column
interaction <- paste(tail(names(selected),-1), collapse = " + ")
f_interaction <- as.formula(
  paste("length", paste("(", single,"+", interaction, ")"), sep = " ~"))

Mfull <- lm(f_interaction, data = train_data)
Mstart <- lm(length ~ ., data = train_data) 

# stepwise AIC
Mstart <- lm(length ~ ., data= train_data)

MAIC_Interaction <- step(object = Mstart,
                         scope = list(lower = M0, upper = Mfull),
                         direction = "both", trace = 0, k = 2)

#stepwiseBIC
MBIC_Interaction <- step(object = Mstart,
                         scope = list(lower = M0, upper = Mfull),
                         direction = "both", trace = 0, 
                         k = log(nrow(train_data)))
```
```{r testmodelsinteractions, echo=FALSE}
# mxn's work
predAICInteraction <- predict(MAIC_Interaction, newdata=test_data)
predBICInteraction <- predict(MBIC_Interaction, newdata=test_data)
AIC_MSPE <- mean((test_data$length - predAICInteraction)^2)
BIC_MSPE <- mean((test_data$length - predBICInteraction)^2)

``` 

```{r printtestinteractionmodels}

MAIC_Interaction #model 1
AIC_MSPE

MBIC_Interaction
BIC_MSPE
``` 

This result shows that the model selected by BIC was preferred as it has a lower MSPE, very generalized, and easy to interpret. At the same time, note that the model chosen by AIC has more parameters but a lower prediction score, this implies that the added parameters added too much variability to the model and seems to have overfitted the training data. Therefore, we decided to use the parameters picked by BIC for our first candidate model, named model 1. The formula of model 1 is:

```{r print model 1 formula}
model1_f <- formula(MBIC_Interaction)
model1_f 
``` 

Furthermore, as we had included only one interaction term in the AIC model and it did not improve the performance of the model. We decided that none of the interaction terms contribute significantly to the outcome of interest (telomere length). In the next part of the analysis, we have removed these terms for simplicity.  

### Reduce Multicolinearity
An additional technique we may use to reduce the impact of multicollinearity on our model is checking variance inflation factor (VIF). As interaction terms were eliminated, we shall regress on all non-categorical covariates and identify those with the largest VIF one at a time until there were no more with 'high' multicollinearity. We used a VIF (Variance Inflation Factor) > 10 as an indicator of "high" multicollinearity (general practice). And after the covariate eliminations, The explanatory variables that remained from the selection are:

```{r vifreduction, echo = FALSE, results='hide', message=FALSE, warning=FALSE}
# est's work
library(car)

current_m <- lm(length ~ . -edu_cat - race_cat - smokenow - male ,data = train_data)
threshold <- 10
covariates <- colnames(train_data)
covariates <- covariates[!(covariates == "length")]
VIFselected<- covariates

while (TRUE){
  VIFS <- as.numeric(vif(current_m))
  max_VIF <- max(VIFS)
  max_idx <- which.max(VIFS)
  if (max_VIF > threshold){
    # update selected
    VIFselected <- VIFselected[-max_idx]
    # update the new model
    f <- as.formula((paste("length", paste(VIFselected, collapse = " + "), sep = " ~")))
    # build the full model starting with all the covariates selcted
    current_m<- lm(f, data = train_data)
  }
  else{
    #stop the loop
    #print("stop")
    break
  }
}
```



```{r printvifreductionresult}
VIFselected
``` 

To validate our parameter selection steps, we could run stepwise selection again on the reduced model.

### Model via Forward-Backward Selection

```{r stepwiseonreducedmodel, echo = FALSE}
# stepwise parameters selection with interaction terms
M0 <- lm(length ~ 1, data = train_data) # minimal model

f_interaction <- as.formula(
  paste("length", paste(VIFselected, collapse = " + "), sep = " ~"))
Mfull <- lm(f_interaction, data = train_data)
Mstart <- lm(f_interaction, data = train_data)

MAIC_reduced <- step(object = Mfull,
                     scope = list(lower = M0, upper = Mfull),
                     direction = "both", trace = 0, k = 2)

#stepwiseBIC
MBIC_reduced <- step(object = Mfull,
                     scope = list(lower = M0, upper = Mfull),
                     direction = "both", trace = 0, 
                     k = log(nrow(train_data)))
``` 

```{r testreducedmodels, echo = FALSE}
predAICReduced <- predict(MAIC_reduced, newdata=test_data)
predBICReduced <- predict(MBIC_reduced, newdata=test_data)
AIC_MSPE <- mean((test_data$length - predAICReduced)^2)
BIC_MSPE <- mean((test_data$length - predBICReduced)^2)
``` 

```{r printreducedtestmodels}
MAIC_reduced
AIC_MSPE

MBIC_reduced
BIC_MSPE
``` 

We got a similar result that the model selected by BIC still outperformed the one selected by AIC. However, this time the stepwise function which ran on the reduced model with BIC had selected different covariates for us. We could build another model, model 2 upon those newly selected covariates.
The formula of model 2 is:
```{r print model 2 formula}
model2_f <-  formula(MBIC_reduced)
model2_f
``` 

### Model via Cross-Validation with Ridge
In order to get accurate prediction evaluations for our models (model 1&2), we used the idea of 80% and 20% train-test split; To ensure the entire training set was covered and each observation was well represented, we divided the training data into 10 folds and repeatedly cross-validated the MSPE. Besides, we performed shrinkage methods like lasso and ridge to solve the overfitting problem. For example, we used ridge with cross validation to update our Model 1&2 as follow: 


```{r ridgeBICcv}
# estella's work cross validation using ridge on BIC model

library(glmnet)
## model 1
Y <-  train_data[, c("length")] 
train_model1_X <-  model.matrix(lm(model1_f, data= train_data))
test_model1_X <- model.matrix(lm(model1_f, data= test_data))

 # use ridge, default 10 folds
cv_ridge_model1 <- cv.glmnet(x = data.matrix(train_model1_X), y = Y, alpha = 0)

paste("model 1")
# estimated betas for min lambda
coef(cv_ridge_model1, s = "lambda.min")
pred_model1 <- predict(cv_ridge_model1, newx = data.matrix(test_model1_X ), s = "lambda.min")

## model 2

Y <-  train_data[, c("length")] 
train_model2_X <-  model.matrix(lm(model2_f, data= train_data))
test_model2_X <- model.matrix(lm(model2_f, data= test_data))

 # use ridge, default 10 folds
cv_ridge_model2 <- cv.glmnet(x = data.matrix(train_model2_X), y = Y, alpha = 0)

paste("model 2")
# estimated betas for min lambda
coef(cv_ridge_model2, s = "lambda.min")
pred_model2 <- predict(cv_ridge_model2, newx = data.matrix(test_model2_X ), s = "lambda.min")

```

With the consideration that lasso could also do parameter selections, we examined sending the remaining covariates in the VIF reduced model alongwith the categorical covariates to ‘glmnet’ function and let it pick the best model for us. We named it model 3.

### Model via Cross-Validation with LASSO

```{r lasso cv}
## estella's work cross validation using lasso to do model selections on reduced model selected by VIF
## model 3
# Load libraries
library(data.table)
library(mltools)

train_df <- as.data.table(train_data[c(VIFselected)])
train_oh <- one_hot(train_df )
test_df <- as.data.table(test_data[c(VIFselected)])
test_oh <- one_hot(test_df )

# try lasso and let lasso do the parameters selection
cvfit_lasso_oh <- cv.glmnet(x = data.matrix(train_oh), y = Y, alpha = 1) # use lasso
coef(cvfit_lasso_oh, s = "lambda.min")
pred_lasso <- predict(cvfit_lasso_oh, newx = data.matrix(test_oh ), s = "lambda.min")

```


# Results
Report on the findings of your analysis

In the end, we looked at the model performance on the remaining test set and computed the MPSE of each model.
```{r model prediction mse }
#model 1
model1_f
mean((test_data$length - pred_model1)^2)
#model 2
model2_f
mean((test_data$length - pred_model2 )^2)
#model 3
paste("lasso selected model:")
mean((test_data$length - pred_lasso)^2)
```

Comparing the MSE of the three different candidates we found earlier, model2 with the formula f = length ~ POP_furan3 + ageyrs has the best performance. As mentioned earlier, this model is also generalized, easy to interpret, and unlikely to get overfitted. We can now answer the question asked in our objective, that the age of the person, and the concentration of foran 3 contribute greatly to the average leukocyte telomere length in a person.



# Discussion
Comment on your findings/conclusions; describe any limitations of your analysis.

We have considered the multicollinearity and interactions within the eleven PCB covariates and similarly for the three dioxin covariates and four furan covariates. However, the multicollinearity and interactions between these eighteen exposure covariates and other covariates are not considered. It is expected that there does not exist any causal relationship between exposure covariates and other covariates since the former relates to the surrounding environment and the latter relates to personal characteristics. For example, it’s believed that the concentration of POP_PCB10 is unrelated to the value of ageyrs and BMI.
 
Besides, a linear regression model has four assumptions, namely linearity, normality, heteroskedasticity and independence. We have analyzed and confirmed that the first three assumptions hold. Generally, we can make the assumption of independence when constructing the model. To further confirm the assumption, time-series data and a closer look at the data collection process will be helpful.




\newpage
# Appendix

## Data Summary \label{datasummary}
Looking at the useful metrics for the data
```{r datasummary}
summary(pollutants)
```

## Boxplots \label{largeboxplots}
```{r boxplots, echo=FALSE}
# Mxn's work
# PCB 1-6
par(mfrow=c(1,6))
boxplot(pollutants[, 2], xlab="PCB 1")
boxplot(pollutants[, 3], xlab="PCB 2")
boxplot(pollutants[, 4], xlab="PCB 3")
boxplot(pollutants[, 5], xlab="PCB 4")
boxplot(pollutants[, 6], xlab="PCB 5")
boxplot(pollutants[, 7], xlab="PCB 6")
```

```{r boxplots2, echo=FALSE}
# PCB 7-11
par(mfrow=c(1,5))
boxplot(pollutants[, 8], xlab="PCB 7")
boxplot(pollutants[, 9], xlab="PCB 8")
boxplot(pollutants[, 10], xlab="PCB 9")
boxplot(pollutants[, 11], xlab="PCB 10")
boxplot(pollutants[, 12], xlab="PCB 11")
```

```{r boxplots3, echo=FALSE}
# Dioxin
par(mfrow=c(1,4))
boxplot(pollutants[, 16], xlab="Furan 1")
boxplot(pollutants[, 17], xlab="Furan 2")
boxplot(pollutants[, 18], xlab="Furan 3")
boxplot(pollutants[, 19], xlab="Furan 4")
```

```{r boxplots4, echo=FALSE}
# Furan
par(mfrow=c(1,3))
boxplot(pollutants[, 13], xlab="Dioxin 1")
boxplot(pollutants[, 14], xlab="Dioxin 2")
boxplot(pollutants[, 15], xlab="Dioxin 3")
```

```{r boxplots5, echo=FALSE}
# white blood cells and concentrations
par(mfrow=c(1,6))
boxplot(pollutants[, 20], xlab="WBC Cnt")
boxplot(pollutants[, 21], xlab="lymph %")
boxplot(pollutants[, 22], xlab="mono %")
boxplot(pollutants[, 23], xlab="eosin %")
boxplot(pollutants[, 24], xlab="baso %")
boxplot(pollutants[, 25], xlab="neutro %")
```

```{r boxplots6, echo=FALSE}
# others
par(mfrow=c(1,4))
boxplot(pollutants[, 26], xlab="BMI")
boxplot(pollutants[, 30], xlab="Age")
boxplot(pollutants[, 31], xlab="Smoke Yrs")
boxplot(pollutants[, 33], xlab="Log cotinine")
```

## Outlier Entries \label{findoutliers}
Here we will find entries where outliers for different covariate occurred.
```{r findPCBoutlier}
pollutant_mat = data.matrix(pollutants, rownames.force = NA)

max_PCB_idx = c()
for (c in 2:12) {
  max_PCB_idx[c-1] = which.max(pollutant_mat[, c])
}
max_PCB_idx
```

```{r findDioxinoutlier}
max_dioxin_idx = c()
for (c in 13:15) {
  max_dioxin_idx[c-12] = which.max(pollutant_mat[, c])
}
max_dioxin_idx
```

```{r findFuranoutlier}
max_furan_idx = c()
for (c in 16:19) {
  max_furan_idx[c-15] = which.max(pollutant_mat[, c])
}
max_furan_idx
```

```{r finfWBCoutlier}
max_WBC_idx = c()
for (c in 20:25) {
  max_WBC_idx[c-19] = which.max(pollutant_mat[, c])
}
max_WBC_idx
```

## AvPlots \label{AvPlots}
```{r avplotSLR}
# testing non-linearity in SLR
# if for any covariate, residual vs x for M1 has a pattern and
# residual vs x for M2 seems random, then y has a nonlinear
# relationship with with x.
# M1: fitting y to x
# M2: fitting y to x^2

par(mfrow=c(1, 3))
outcome <- pollutants$length
check <- function(x) {
  M1 <- lm(outcome ~ x)
  print(paste("residual for M1: ", sigma(M1)))
  M2 <- lm(outcome ~ x + I(x^2))
  print(paste("residual for M2: ", sigma(M2)))
  plot(x, M1$residual)
  plot(x, M2$residual)
  plot(x, outcome)
}

list <- list(pollutants$ageyrs, pollutants$yrssmoke,
             pollutants$BMI, pollutants$ln_lbxcot,
             pollutants$whitecell_count, pollutants$lymphocyte_pct, 
             pollutants$monocyte_pct, pollutants$eosinophils_pct, 
             pollutants$basophils_pct, pollutants$neutrophils_pct)
for (column in list) {
  check(column)
}
```

```{r avplotMLR}
# testing non-linearity in MLR
library(car)
M <- lm (length ~ ., data=pollutants)
avPlots(M, main="Added-Variable Plot")
```

## Residuals vs Fitted plot \label{Residuals vs Fitted plot}
```{r residuals vs fitted}
# Heteroskedasticity
## fit model
Mh <- lm(length ~ . - smokenow - race_cat
         - edu_cat - male , data = pollutants)
## residuals
res1 <- resid(Mh) # raw residuals
stud1 <- res1/(sigma(Mh)*sqrt(1-hatvalues(Mh))) # studentized residuals

## plot of studentized residuals vs fitted values
plot(stud1~fitted(Mh),
     xlab="Fitted Vals",
     ylab="Studentized Residuals",
     main="Residuals vs Fitted")

```

## Histograms and QQ plot \label{Normal plot}
```{r histofresiduals}
par(mfrow = c(1, 2))
## plot distribution of studentized residuals
hist(stud1,breaks=12,
     probability=TRUE,xlim=c(-4,4),
     xlab="Studentized Residuals",
     main="Distribution of Residuals")
grid <- seq(-3.5,3.5,by=0.05)
lines(x=grid,y=dnorm(grid),col="blue") # add N(0,1) pdf

## qqplot of studentized residuals
qqnorm(stud1)
abline(0,1) 
```



## Model Summaries 
comments by Estella:
!need to revise, now we only have 3 models, see result above for more information 


### Models Selected with Interactions \label{modelsummary1}
```{r printModelSummaries1}
# stepwiseB_Adjusted R2
# summary(cv_ridge_model1)
# summary(MBIC_Interaction)
```

### Models after VIF Selection \label{modelsummary2}
```{r printModelSummaries2}
# summary(MAIC_reduced)
# summary(MBIC_reduced)
```

